# -*- coding: utf-8 -*-
"""kairu-6hafta-denetimsiz-ogrenme.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pXnac8FgjIGmH7LAyYb8qz7FrkVgIo1E
"""

import pandas as pd

#veri seti
df_train = pd.read_csv("/content/drive/MyDrive/UNSW_NB15_training-set.csv")

# hedef sütun: 'label' (0:nrmal, 1: attack)
print(f"toplam örnek: {len(df_train)}")
print(f"Saldırı oranı: {df_train['label'].mean():.2%}")

"""**Örneklem Seçimi (İşlenebilirlik için)**

Büyük veri setiyle çalışmak zaman alıcı olabilir. Bu nedenle:

**2000 normal bağlantı**(label=0)

**500 saldırı bağlantısı**  (label=1)
"""

normal = df_train[df_train['label'] == 0].sample(2000, random_state=42)
attack = df_train[df_train['label'] == 1].sample(500, random_state=42)
df_sample = pd.concat([normal, attack]).reset_index(drop=True)

"""**2. Ön İşleme**

**Kategorik Verilerin Dönüşümü**

Veri setinde proto, service, state gibi kategorik sütunlar var. Bunlar:

One-Hot Encoding ile dönüştürüldü.

Alternatif olarak, Target Encoding veya Embedding kullanılabilirdi, ancak burada basitlik için One-Hot tercih edildi.
"""

from sklearn.preprocessing import OneHotEncoder

categorical_cols = ['proto', 'service', 'state']
encoder = OneHotEncoder(sparse_output=False, drop='first')
encoded_cats = encoder.fit_transform(df_sample[categorical_cols])
encoded_df = pd.DataFrame(encoded_cats, columns=encoder.get_feature_names_out(categorical_cols))

"""**Sayısal Sütunların Ölçeklendirilmesi**

Sayısal sütunlar (örneğin: dur, sbytes, dbytes, sttl, dttl) farklı ölçeklerde.
Bu nedenle:
"""

from sklearn.preprocessing import StandardScaler

numeric_cols = ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sload', 'dload', 'spkts', 'dpkts']
scaler = StandardScaler()
scaled_numeric = scaler.fit_transform(df_sample[numeric_cols])
scaled_df = pd.DataFrame(scaled_numeric, columns=[f"scale_{col}" for col in numeric_cols])

"""**Veri Birleştirme**"""

X = pd.concat([scaled_df, encoded_df], axis=1)  # Özellik matrisi
y_true = df_sample['label']  # Gerçek etiketler (sadece değerlendirme için)

"""**3. DBSCAN ile Anomali Tespiti**

Mantık:
DBSCAN, yoğunluk temelli bir kümeleme algoritmasıdır. Yoğun bölgelerden uzakta kalan noktaları gürültü (noise) olarak işaretler. Bu gürültü, bizim için anomali (saldırı) olabilir.


Hiperparametre Ayarı

**eps:** Komşuluk yarıçapı. Küçük değerler fazla gürültü, büyükler fazla küme yapar.

**min_samples:** Bir noktanın çekirdek olabilmesi için gerekli komşu sayısı.
"""

from sklearn.cluster import DBSCAN

# eps = 0.8, min_samples = 5 (deneme-yanılma ile optimize edildi)
dbscan = DBSCAN(eps=0.8, min_samples=5)
y_pred_dbscan = dbscan.fit_predict(X)

# DBSCAN çıktısı: -1 = gürültü (anomali), diğerleri küme numarası
y_pred_anomaly = (y_pred_dbscan == -1).astype(int)

"""**PCA ile Görselleştirme**

Boyut indirgeme ile 2D’de dağılım:
"""

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

plt.figure(figsize=(10, 6))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred_dbscan, cmap='coolwarm', s=10)
plt.title("DBSCAN Sonuçları (PCA ile 2D)")
plt.colorbar(scatter, label='Küme / Gürültü')
plt.xlabel("Bileşen 1")
plt.ylabel("Bileşen 2")
plt.show()

"""**4. Isolation Forest ile Anomali Tespiti**

Mantık:

Isolation Forest, anormallikleri kolay izole edilebilir noktalar olarak görür. Normal veriler karmaşık karar yolları gerektirirken, anormaller az sayıda bölünmeyle ayrılır.


**Hiperparametre Ayarı**

contamination: Veri setindeki tahmini anomali oranı. UNSW-NB15’te yaklaşık %20 saldırı var → contamination=0.2
"""

from sklearn.ensemble import IsolationForest

iso_forest = IsolationForest(contamination=0.2, random_state=42, n_estimators=100)
y_pred_iso = iso_forest.fit_predict(X)

# -1 = anomali, 1 = normal → 0 ve 1'e çevir
y_pred_iso_binary = (y_pred_iso == -1).astype(int)

"""**5. Model Karşılaştırması**

Metrikler
"""

from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

def evaluate(y_true, y_pred, name):
    print(f"\n--- {name} Sonuçları ---")
    print(f"Precision: {precision_score(y_true, y_pred):.3f}")
    print(f"Recall: {recall_score(y_true, y_pred):.3f}")
    print(f"F1-Score: {f1_score(y_true, y_pred):.3f}")
    print(f"Doğruluk: {accuracy_score(y_true, y_pred):.3f}")

evaluate(y_true, y_pred_anomaly, "DBSCAN")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import numpy as np

def detailed_report(y_true, y_pred, model_name):
    print(f"\n========== {model_name} SONUÇLARI ==========")
    print(f"Gerçek Saldırı Sayısı: {np.sum(y_true)}")
    print(f"Tahmin Edilen Anomali Sayısı: {np.sum(y_pred)}")

    cm = confusion_matrix(y_true, y_pred)
    print(f"\n[Confusion Matrix]")
    print("                Tahmin: Normal | Saldırı")
    print("Gerçek: Normal     ", cm[0][0], "      ", cm[0][1])
    print("        Saldırı     ", cm[1][0], "      ", cm[1][1])

    prec = precision_score(y_true, y_pred)
    rec = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    print(f"\n[Metrikler]")
    print(f"Precision (Kesinlik)  : {prec:.4f}")
    print(f"Recall (Duyarlılık)    : {rec:.4f}")
    print(f"F1-Score                : {f1:.4f}")
    print(f"Accuracy (Doğruluk)     : {acc:.4f}")

detailed_report(y_true, y_pred_anomaly, "DBSCAN")