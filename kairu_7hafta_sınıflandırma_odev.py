# -*- coding: utf-8 -*-
"""kairu-7hafta-sÄ±nÄ±flandÄ±rma-odev.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mz9wz-1OfBlaWCDEIy01W-BJ-blfF6zm
"""

!pip install catboost

"""1. Gerekli KÃ¼tÃ¼phaneleri YÃ¼kle"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""2. Veriyi YÃ¼kle ve Ä°ncele"""

df = pd.read_csv('Pokemon.csv')

# Ä°lk 5 satÄ±rÄ± gÃ¶ster
print(df.head())
print(df.info())
print(df.isnull().sum())

columns = ['#', 'Name', 'Type 1', 'Type 2', 'Total', 'HP', 'Attack', 'Defense',
           'Sp. Atk', 'Sp. Def', 'Speed', 'Generation', 'Legendary']

df = pd.read_csv('Pokemon.csv', names=columns, header=0)  # Ä°lk satÄ±rÄ± baÅŸlÄ±k kabul et

"""3. Veri Ã–n Ä°ÅŸleme (Preprocessing)"""

def preprocess_pokemon_data(df):
    # Kopya al
    df = df.copy()

    # 'Legendary' sÃ¼tununu boolean'dan int'e Ã§evir
    df['Legendary'] = df['Legendary'].astype(int)

    # 'Type 2' eksik deÄŸerlerini 'None' ile doldur
    df['Type 2'].fillna('None', inplace=True)

    # Kategorik sÃ¼tunlarÄ± encode et: Type 1, Type 2, Name (isteÄŸe baÄŸlÄ±)
    le = LabelEncoder()
    df['Type 1'] = le.fit_transform(df['Type 1'])
    df['Type 2'] = le.fit_transform(df['Type 2'])

    # 'Name' sÃ¼tunu Ã§ok fazla benzersiz deÄŸer iÃ§erir, genellikle Ã§Ä±karÄ±lÄ±r
    # Mega, Primal, Forme gibi varyasyonlarÄ± temizlemek isteyebiliriz ama ÅŸimdilik Ã§Ä±karalÄ±m
    df.drop(['Name', '#'], axis=1, inplace=True)

    # Ã–zellik mÃ¼hendisliÄŸi: Toplam statlar zaten 'Total' de var ama diÄŸerleri de kullanÄ±labilir
    # Yeni Ã¶zellikler: Attack/Defense oranÄ±, Speed/HP oranÄ± vs.
    df['Attack_Defense_Ratio'] = df['Attack'] / (df['Defense'] + 1)  # +1 bÃ¶lme hatkÄ±sÄ±nÄ± Ã¶nler
    df['Speed_Hp_Ratio'] = df['Speed'] / (df['HP'] + 1)
    df['Special_Attack_Defense'] = df['Sp. Atk'] + df['Sp. Def']
    df['Physical_Special_Balance'] = df['Attack'] - df['Sp. Atk']

    return df

# Veriyi iÅŸle
df_processed = preprocess_pokemon_data(df)
print(df_processed.head())

"""4. Ã–zellik ve Hedef AyÄ±rma"""

X = df_processed.drop('Legendary', axis=1)
y = df_processed['Legendary']  # Hedef: 1 = Legendary, 0 = Normal

# EÄŸitim ve test seti ayÄ±rma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""5. Modelleri TanÄ±mla"""

models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "SVM": Pipeline([
        ('scaler', StandardScaler()),
        ('svm', SVC(random_state=42))
    ]),
    "KNN": Pipeline([
        ('scaler', StandardScaler()),
        ('knn', KNeighborsClassifier())
    ]),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "LightGBM": LGBMClassifier(random_state=42, verbose=-1),
    "CatBoost": CatBoostClassifier(random_state=42, verbose=False)
}

""" 6. Modelleri EÄŸit ve DeÄŸerlendir"""

results = {}

for name, model in models.items():
    print(f"\n{name} modeli eÄŸitiliyor...")

    # EÄŸitim
    model.fit(X_train, y_train)

    # Tahmin
    y_pred = model.predict(X_test)

    # DeÄŸerlendirme
    acc = accuracy_score(y_test, y_pred)
    results[name] = {
        'accuracy': acc,
        'classification_report': classification_report(y_test, y_pred),
        'confusion_matrix': confusion_matrix(y_test, y_pred)
    }

    # SonuÃ§ yazdÄ±r
    print(f"{name} DoÄŸruluk: {acc:.4f}")
    print(f"\n{results[name]['classification_report']}")

    # KarmaÅŸÄ±klÄ±k matrisi gÃ¶rselleÅŸtir
    plt.figure(figsize=(6, 5))
    sns.heatmap(results[name]['confusion_matrix'], annot=True, fmt='d', cmap='Blues')
    plt.title(f'{name} - KarmaÅŸÄ±klÄ±k Matrisi')
    plt.ylabel('GerÃ§ek')
    plt.xlabel('Tahmin')
    plt.show()

"""7. En Ä°yi Modeli Belirle"""

best_model_name = max(results, key=lambda x: results[x]['accuracy'])
print(f"\nâœ… En iyi model: {best_model_name} (DoÄŸruluk: {results[best_model_name]['accuracy']:.4f})")

"""8. Hiperparametre Optimizasyonu (GridSearchCV)"""

# Hiperparametre grid'leri
param_grids = {
    "Random Forest": {
        'n_estimators': [100, 200],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5]
    },
    "Logistic Regression": {
        'C': [0.1, 1, 10],
        'penalty': ['l2']
    },
    "SVM": {
        'svm__C': [0.1, 1, 10],
        'svm__kernel': ['rbf', 'linear']
    },
    "KNN": {
        'knn__n_neighbors': [3, 5, 7],
        'knn__weights': ['uniform', 'distance']
    },
    "XGBoost": {
        'n_estimators': [100, 200],
        'max_depth': [3, 5],
        'learning_rate': [0.1, 0.2]
    },
    "LightGBM": {
        'n_estimators': [100, 200],
        'num_leaves': [31, 50],
        'learning_rate': [0.1, 0.2]
    },
    "CatBoost": {
        'iterations': [100, 200],
        'depth': [4, 6],
        'learning_rate': [0.1, 0.2]
    }
}

# En iyi model iÃ§in GridSearch
best_model = models[best_model_name]
param_grid = param_grids[best_model_name]

grid_search = GridSearchCV(
    estimator=best_model,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

print(f"\nğŸ” {best_model_name} iÃ§in hiperparametre optimizasyonu baÅŸlÄ±yor...")
grid_search.fit(X_train, y_train)

print("En iyi parametreler:", grid_search.best_params_)
print("En iyi CV skoru:", grid_search.best_score_)

# Test seti Ã¼zerinde deÄŸerlendirme
best_final_model = grid_search.best_estimator_
y_pred_opt = best_final_model.predict(X_test)
print("Optimize edilmiÅŸ model test doÄŸruluÄŸu:", accuracy_score(y_test, y_pred_opt))

"""9. TÃ¼m Modellerin KarÅŸÄ±laÅŸtÄ±rmasÄ±"""

accuracies = {name: results[name]['accuracy'] for name in results}

plt.figure(figsize=(10, 6))
sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()))
plt.title('Model DoÄŸruluk KarÅŸÄ±laÅŸtÄ±rmasÄ±')
plt.ylabel('DoÄŸruluk')
plt.xticks(rotation=45)
plt.ylim(0.8, 1.0)
plt.show()