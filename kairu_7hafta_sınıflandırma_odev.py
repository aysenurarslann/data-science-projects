# -*- coding: utf-8 -*-
"""kairu-7hafta-sınıflandırma-odev.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mz9wz-1OfBlaWCDEIy01W-BJ-blfF6zm
"""

!pip install catboost

"""1. Gerekli Kütüphaneleri Yükle"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

"""2. Veriyi Yükle ve İncele"""

df = pd.read_csv('Pokemon.csv')

# İlk 5 satırı göster
print(df.head())
print(df.info())
print(df.isnull().sum())

columns = ['#', 'Name', 'Type 1', 'Type 2', 'Total', 'HP', 'Attack', 'Defense',
           'Sp. Atk', 'Sp. Def', 'Speed', 'Generation', 'Legendary']

df = pd.read_csv('Pokemon.csv', names=columns, header=0)  # İlk satırı başlık kabul et

"""3. Veri Ön İşleme (Preprocessing)"""

def preprocess_pokemon_data(df):
    # Kopya al
    df = df.copy()

    # 'Legendary' sütununu boolean'dan int'e çevir
    df['Legendary'] = df['Legendary'].astype(int)

    # 'Type 2' eksik değerlerini 'None' ile doldur
    df['Type 2'].fillna('None', inplace=True)

    # Kategorik sütunları encode et: Type 1, Type 2, Name (isteğe bağlı)
    le = LabelEncoder()
    df['Type 1'] = le.fit_transform(df['Type 1'])
    df['Type 2'] = le.fit_transform(df['Type 2'])

    # 'Name' sütunu çok fazla benzersiz değer içerir, genellikle çıkarılır
    # Mega, Primal, Forme gibi varyasyonları temizlemek isteyebiliriz ama şimdilik çıkaralım
    df.drop(['Name', '#'], axis=1, inplace=True)

    # Özellik mühendisliği: Toplam statlar zaten 'Total' de var ama diğerleri de kullanılabilir
    # Yeni özellikler: Attack/Defense oranı, Speed/HP oranı vs.
    df['Attack_Defense_Ratio'] = df['Attack'] / (df['Defense'] + 1)  # +1 bölme hatkısını önler
    df['Speed_Hp_Ratio'] = df['Speed'] / (df['HP'] + 1)
    df['Special_Attack_Defense'] = df['Sp. Atk'] + df['Sp. Def']
    df['Physical_Special_Balance'] = df['Attack'] - df['Sp. Atk']

    return df

# Veriyi işle
df_processed = preprocess_pokemon_data(df)
print(df_processed.head())

"""4. Özellik ve Hedef Ayırma"""

X = df_processed.drop('Legendary', axis=1)
y = df_processed['Legendary']  # Hedef: 1 = Legendary, 0 = Normal

# Eğitim ve test seti ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

"""5. Modelleri Tanımla"""

models = {
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "SVM": Pipeline([
        ('scaler', StandardScaler()),
        ('svm', SVC(random_state=42))
    ]),
    "KNN": Pipeline([
        ('scaler', StandardScaler()),
        ('knn', KNeighborsClassifier())
    ]),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "LightGBM": LGBMClassifier(random_state=42, verbose=-1),
    "CatBoost": CatBoostClassifier(random_state=42, verbose=False)
}

""" 6. Modelleri Eğit ve Değerlendir"""

results = {}

for name, model in models.items():
    print(f"\n{name} modeli eğitiliyor...")

    # Eğitim
    model.fit(X_train, y_train)

    # Tahmin
    y_pred = model.predict(X_test)

    # Değerlendirme
    acc = accuracy_score(y_test, y_pred)
    results[name] = {
        'accuracy': acc,
        'classification_report': classification_report(y_test, y_pred),
        'confusion_matrix': confusion_matrix(y_test, y_pred)
    }

    # Sonuç yazdır
    print(f"{name} Doğruluk: {acc:.4f}")
    print(f"\n{results[name]['classification_report']}")

    # Karmaşıklık matrisi görselleştir
    plt.figure(figsize=(6, 5))
    sns.heatmap(results[name]['confusion_matrix'], annot=True, fmt='d', cmap='Blues')
    plt.title(f'{name} - Karmaşıklık Matrisi')
    plt.ylabel('Gerçek')
    plt.xlabel('Tahmin')
    plt.show()

"""7. En İyi Modeli Belirle"""

best_model_name = max(results, key=lambda x: results[x]['accuracy'])
print(f"\n✅ En iyi model: {best_model_name} (Doğruluk: {results[best_model_name]['accuracy']:.4f})")

"""8. Hiperparametre Optimizasyonu (GridSearchCV)"""

# Hiperparametre grid'leri
param_grids = {
    "Random Forest": {
        'n_estimators': [100, 200],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5]
    },
    "Logistic Regression": {
        'C': [0.1, 1, 10],
        'penalty': ['l2']
    },
    "SVM": {
        'svm__C': [0.1, 1, 10],
        'svm__kernel': ['rbf', 'linear']
    },
    "KNN": {
        'knn__n_neighbors': [3, 5, 7],
        'knn__weights': ['uniform', 'distance']
    },
    "XGBoost": {
        'n_estimators': [100, 200],
        'max_depth': [3, 5],
        'learning_rate': [0.1, 0.2]
    },
    "LightGBM": {
        'n_estimators': [100, 200],
        'num_leaves': [31, 50],
        'learning_rate': [0.1, 0.2]
    },
    "CatBoost": {
        'iterations': [100, 200],
        'depth': [4, 6],
        'learning_rate': [0.1, 0.2]
    }
}

# En iyi model için GridSearch
best_model = models[best_model_name]
param_grid = param_grids[best_model_name]

grid_search = GridSearchCV(
    estimator=best_model,
    param_grid=param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

print(f"\n🔍 {best_model_name} için hiperparametre optimizasyonu başlıyor...")
grid_search.fit(X_train, y_train)

print("En iyi parametreler:", grid_search.best_params_)
print("En iyi CV skoru:", grid_search.best_score_)

# Test seti üzerinde değerlendirme
best_final_model = grid_search.best_estimator_
y_pred_opt = best_final_model.predict(X_test)
print("Optimize edilmiş model test doğruluğu:", accuracy_score(y_test, y_pred_opt))

"""9. Tüm Modellerin Karşılaştırması"""

accuracies = {name: results[name]['accuracy'] for name in results}

plt.figure(figsize=(10, 6))
sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()))
plt.title('Model Doğruluk Karşılaştırması')
plt.ylabel('Doğruluk')
plt.xticks(rotation=45)
plt.ylim(0.8, 1.0)
plt.show()